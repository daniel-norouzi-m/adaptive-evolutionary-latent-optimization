{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import necessary modules \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from numpy.linalg import eigvalsh\n",
    "from plotly.subplots import make_subplots\n",
    "import torch\n",
    "\n",
    "from rbf_volatility_surface import RBFVolatilitySurface\n",
    "from smoothness_prior import RBFQuadraticSmoothnessPrior\n",
    "from dataset_sabr import generate_sabr_call_options\n",
    "from dupire_pinn_trainer import DupirePINNTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the strike price list and maturity time list\n",
    "strike_price_list = np.array([0.75, 0.85, 0.9, 0.95, 1.0, 1.05, 1.1, 1.2, 1.3, 1.5])\n",
    "maturity_time_list = np.array([0.02, 0.08, 0.17, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0])\n",
    "\n",
    "# Create the product grid of maturity times and strike prices\n",
    "product_grid = list(product(maturity_time_list, strike_price_list))\n",
    "maturity_times, strike_prices = zip(*product_grid)\n",
    "\n",
    "# Convert to arrays for further operations\n",
    "maturity_times = np.array(maturity_times)\n",
    "strike_prices = np.array(strike_prices)\n",
    "\n",
    "# Variance formula for log-uniform distribution\n",
    "def log_uniform_variance(a, b):\n",
    "    log_term = np.log(b / a)\n",
    "    var = ((b ** 2 - a ** 2) / (2 * log_term)) - ((b - a) / log_term) ** 2\n",
    "    return var\n",
    "\n",
    "# Calculate standard deviations for maturity times and strike prices\n",
    "maturity_std = np.sqrt(log_uniform_variance(maturity_time_list.min(), maturity_time_list.max()))\n",
    "strike_std = np.sqrt(log_uniform_variance(strike_price_list.min(), strike_price_list.max()))\n",
    "\n",
    "# Define the SABR model parameters\n",
    "alpha = 0.20  # Stochastic volatility parameter\n",
    "beta = 0.50   # Elasticity parameter\n",
    "rho = -0.75   # Correlation between asset price and volatility\n",
    "nu = 1.0      # Volatility of volatility parameter\n",
    "\n",
    "# Other model parameters\n",
    "risk_free_rate = np.log(1.02)  # Risk-free interest rate\n",
    "underlying_price = 1.0         # Current price of the underlying asset\n",
    "\n",
    "# Generate the dataset using the SABR model and Black-Scholes formula\n",
    "call_option_dataset = generate_sabr_call_options(\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    rho=rho,\n",
    "    nu=nu,\n",
    "    maturity_times=maturity_times,\n",
    "    strike_prices=strike_prices,\n",
    "    risk_free_rate=risk_free_rate,\n",
    "    underlying_price=underlying_price\n",
    ")\n",
    "\n",
    "# Maturity times and strike prices from the previous product grid setup\n",
    "hypothetical_maturity_time_list = np.logspace(np.log10(0.01), np.log10(3.1), 100)\n",
    "hypothetical_strike_price_list = np.logspace(np.log10(0.7), np.log10(1.75), 100)\n",
    "\n",
    "# Create the product grid of maturity times and strike prices\n",
    "hypothetical_product_grid = list(product(hypothetical_maturity_time_list, hypothetical_strike_price_list))\n",
    "hypothetical_maturity_times, hypothetical_strike_prices = zip(*hypothetical_product_grid)\n",
    "hypothetical_maturity_times, hypothetical_strike_prices = np.array(hypothetical_maturity_times), np.array(hypothetical_strike_prices)\n",
    "\n",
    "# Reshape the data for 3D surface plotting\n",
    "hypothetical_maturities_grid = hypothetical_maturity_times.reshape((len(hypothetical_maturity_time_list), len(hypothetical_strike_price_list)))  \n",
    "hypothetical_strikes_grid = hypothetical_strike_prices.reshape((len(hypothetical_maturity_time_list), len(hypothetical_strike_price_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_roots = 350\n",
    "smoothness_controller = 3.274549162877732e-05\n",
    "\n",
    "# Initialize the RBFQuadraticSmoothnessPrior class\n",
    "smoothness_prior = RBFQuadraticSmoothnessPrior(\n",
    "    maturity_times=maturity_times,\n",
    "    strike_prices=strike_prices,\n",
    "    maturity_std=maturity_std,\n",
    "    strike_std=strike_std,\n",
    "    n_roots=n_roots,\n",
    "    smoothness_controller=smoothness_controller,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "# The constant_volatility is set to a reasonable value\n",
    "constant_volatility = RBFVolatilitySurface.calculate_constant_volatility(\n",
    "    call_option_dataset[\"Implied Volatility\"],\n",
    "    call_option_dataset[\"Time to Maturity\"],\n",
    "    call_option_dataset[\"Strike Price\"],\n",
    "    risk_free_rate,\n",
    "    underlying_price\n",
    ")\n",
    "\n",
    "sampled_surface_coefficients = smoothness_prior.sample_smooth_surfaces(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the sampled coefficients \n",
    "sampled_volatilities = []\n",
    "for coefficients in sampled_surface_coefficients:\n",
    "    \n",
    "    # Initialize the RBFVolatilitySurface class for each set of coefficients\n",
    "    rbf_surface = RBFVolatilitySurface(\n",
    "        coefficients=coefficients,\n",
    "        maturity_times=maturity_times,\n",
    "        strike_prices=strike_prices,\n",
    "        maturity_std=maturity_std,\n",
    "        strike_std=strike_std,\n",
    "        constant_volatility=constant_volatility\n",
    "    )\n",
    "\n",
    "    # Generate the volatility surface over the product grid of times and strikes\n",
    "    surface_volatilities = [\n",
    "        rbf_surface.implied_volatility_surface(T, K)\n",
    "        for T, K in product_grid\n",
    "    ]\n",
    "    sampled_volatilities.extend(surface_volatilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 128\n",
    "n_layers = 4\n",
    "batch_size = 100\n",
    "pde_loss_coefficient = 1.0\n",
    "maturity_zero_loss_coefficient = 100\n",
    "strike_zero_loss_coefficient = 100\n",
    "strike_infinity_loss_coefficient = 100\n",
    "pre_train_learning_rate = 1e-3\n",
    "fine_tune_learning_rate = 1e-4\n",
    "pre_train_epochs = 50\n",
    "fine_tune_epochs = 20\n",
    "maturity_min = maturity_time_list.min()\n",
    "maturity_max = maturity_time_list.max()\n",
    "strike_min = strike_price_list.min()\n",
    "strike_max = strike_price_list.max()\n",
    "volatility_mean = np.mean(sampled_volatilities)\n",
    "volatility_std = np.std(sampled_volatilities)\n",
    "constant_volatility = False\n",
    "strike_infinity = 2.5\n",
    "device = 'cpu'\n",
    "\n",
    "# Initialize the DupirePINNTrainer class\n",
    "trainer = DupirePINNTrainer(\n",
    "    hidden_dim=hidden_dim,\n",
    "    n_layers=n_layers,\n",
    "    batch_size=batch_size,\n",
    "    pde_loss_coefficient=pde_loss_coefficient,\n",
    "    maturity_zero_loss_coefficient=maturity_zero_loss_coefficient,\n",
    "    strike_zero_loss_coefficient=strike_zero_loss_coefficient,\n",
    "    strike_infinity_loss_coefficient=strike_infinity_loss_coefficient,\n",
    "    pre_train_learning_rate=pre_train_learning_rate,\n",
    "    fine_tune_learning_rate=fine_tune_learning_rate,\n",
    "    pre_train_epochs=pre_train_epochs,\n",
    "    fine_tune_epochs=fine_tune_epochs,\n",
    "    maturity_min=maturity_min,\n",
    "    maturity_max=maturity_max,\n",
    "    strike_min=strike_min,\n",
    "    strike_max=strike_max,\n",
    "    volatility_mean=volatility_mean,\n",
    "    volatility_std=volatility_std,\n",
    "    maturity_time_list=maturity_time_list,\n",
    "    strike_price_list=strike_price_list,\n",
    "    strike_std=strike_std,\n",
    "    maturity_std=maturity_std,\n",
    "    constant_volatility=constant_volatility,\n",
    "    strike_infinity=strike_infinity,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([130])\n",
      "torch.Size([130, 10])\n",
      "tensor([0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200, 0.0200,\n",
      "        0.0200, 0.0800, 0.0800, 0.0800, 0.0800, 0.0800, 0.0800, 0.0800, 0.0800,\n",
      "        0.0800, 0.0800, 0.1700, 0.1700, 0.1700, 0.1700, 0.1700, 0.1700, 0.1700,\n",
      "        0.1700, 0.1700, 0.1700, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500,\n",
      "        0.2500, 0.2500, 0.2500, 0.2500, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.7500, 0.7500, 0.7500, 0.7500,\n",
      "        0.7500, 0.7500, 0.7500, 0.7500, 0.7500, 0.7500, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.5000, 1.5000,\n",
      "        1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 1.5000, 2.0000,\n",
      "        2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000,\n",
      "        3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000, 3.0000,\n",
      "        3.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0200, 0.0800, 0.1700, 0.2500, 0.5000, 0.7500, 1.0000,\n",
      "        1.5000, 2.0000, 3.0000, 0.0200, 0.0800, 0.1700, 0.2500, 0.5000, 0.7500,\n",
      "        1.0000, 1.5000, 2.0000, 3.0000])\n",
      "tensor([[-4.4703e-10, -6.0000e-02, -1.5000e-01,  ..., -1.4800e+00,\n",
      "         -1.9800e+00, -2.9800e+00],\n",
      "        [-4.4703e-10, -6.0000e-02, -1.5000e-01,  ..., -1.4800e+00,\n",
      "         -1.9800e+00, -2.9800e+00],\n",
      "        [-4.4703e-10, -6.0000e-02, -1.5000e-01,  ..., -1.4800e+00,\n",
      "         -1.9800e+00, -2.9800e+00],\n",
      "        ...,\n",
      "        [ 1.4800e+00,  1.4200e+00,  1.3300e+00,  ...,  0.0000e+00,\n",
      "         -5.0000e-01, -1.5000e+00],\n",
      "        [ 1.9800e+00,  1.9200e+00,  1.8300e+00,  ...,  5.0000e-01,\n",
      "          0.0000e+00, -1.0000e+00],\n",
      "        [ 2.9800e+00,  2.9200e+00,  2.8300e+00,  ...,  1.5000e+00,\n",
      "          1.0000e+00,  0.0000e+00]], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, got input (130), mat (130x10), vec (100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampled_surface_coefficients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampled_surface_coefficients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minitial test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/scikit_learn_data/evolutionary-latent-optimization/dupire_pinn_trainer.py:191\u001b[0m, in \u001b[0;36mDupirePINNTrainer.pre_train\u001b[0;34m(self, sampled_surface_coefficients, experiment_name)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03mPre-train the PINN model.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m- experiment_name: If provided, logs will be recorded in TensorBoard with this experiment name.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_train_loss_history \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPDE Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZero Maturity Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    189\u001b[0m }\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampled_surface_coefficients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_train_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_train_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_train_loss_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/scikit_learn_data/evolutionary-latent-optimization/dupire_pinn_trainer.py:107\u001b[0m, in \u001b[0;36mDupirePINNTrainer._train\u001b[0;34m(self, sampled_surface_coefficients, n_epochs, optimizer, loss_history, experiment_name)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Begin training\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (time_to_maturity, strike_price, implied_volatility) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;66;03m# Move data to the appropriate device\u001b[39;00m\n\u001b[1;32m    109\u001b[0m         time_to_maturity \u001b[38;5;241m=\u001b[39m time_to_maturity\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    110\u001b[0m         strike_price \u001b[38;5;241m=\u001b[39m strike_price\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/anaconda3/envs/Apache/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/Apache/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/Apache/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/Apache/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/scikit_learn_data/evolutionary-latent-optimization/rbf_volatility_surface.py:236\u001b[0m, in \u001b[0;36mSurfaceDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Disable gradient tracking while computing the implied volatility tensor\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 236\u001b[0m     implied_volatility_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mrbf_surface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimplied_volatility_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_to_maturity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# detach to ensure grads are not tracked\u001b[39;49;00m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrike_price\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# detach to ensure grads are not tracked\u001b[39;49;00m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m# Return the tensors needed for training (time_to_maturity, strike_price, implied_volatility)\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_to_maturity, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrike_price, implied_volatility_tensor\n",
      "File \u001b[0;32m~/scikit_learn_data/evolutionary-latent-optimization/rbf_volatility_surface.py:95\u001b[0m, in \u001b[0;36mRBFVolatilitySurface.implied_volatility_tensor\u001b[0;34m(self, time_to_maturity_tensor, strike_price_tensor)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mprint\u001b[39m((time_to_maturity_tensor\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m maturity_times_tensor))\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Compute the weighted sum of the RBF values\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m rbf_sum \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrbf_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoefficients_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Compute the implied volatility: constant volatility + RBF sum\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstant_volatility \u001b[38;5;241m+\u001b[39m rbf_sum\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, got input (130), mat (130x10), vec (100)"
     ]
    }
   ],
   "source": [
    "trainer.pre_train(\n",
    "    sampled_surface_coefficients=sampled_surface_coefficients,\n",
    "    experiment_name='initial test'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
